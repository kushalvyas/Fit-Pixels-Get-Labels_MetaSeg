{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3e82dd5",
   "metadata": {},
   "source": [
    "## MetaSeg implementation for 2D MRI segmentation using 5 classes (including background). \n",
    "\n",
    "Dataset: We use the [OASIS-MRI Neurite dataset](https://github.com/adalca/medical-datasets/blob/master/neurite-oasis.md).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd657021",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635e5eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(422)\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1175f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path as osp\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215401e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, os.path as osp\n",
    "import torch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import alpine\n",
    "\n",
    "# import libINR.models, libINR.utils\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06a9b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../modules')\n",
    "sys.path.append(\"..\")\n",
    "from learner import INRMetaLearner\n",
    "import dataloaders\n",
    "\n",
    "import models\n",
    "import loss_functions\n",
    "import metrics\n",
    "import utils\n",
    "import vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a10fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"../config/oasis_splits.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8194b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_data = json.load(open(config_file, 'r'))\n",
    "train_files = files_data['train']\n",
    "val_files = files_data['val']\n",
    "test_files = files_data['test']\n",
    "\n",
    "\n",
    "# check overlap for any samples.\n",
    "print(len(train_files), len(val_files), len(test_files))\n",
    "set_train = set([x['img'] for x in train_files])\n",
    "set_val = set([x['img'] for x in val_files])\n",
    "set_test = set([x['img'] for x in test_files])\n",
    "\n",
    "if len(set_train.intersection(set_val)) > 0 or  len(set_train.intersection(set_test)) > 0 or  len(set_val.intersection(set_test)) > 0:\n",
    "    print(\"WARNING: OVERLAPPING DATA SPLITS\")\n",
    "else:\n",
    "    print(\"No overlap in data splits. GOOD TO GO!!!!!!!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eee705",
   "metadata": {},
   "outputs": [],
   "source": [
    "INNER_STEPS = 2\n",
    "RANDOM_AUGMENT = False\n",
    "RES = 192\n",
    "TEST_RUN_STEPS = VAL_STEPS  = 100# 2 #100#50\n",
    "VAL_META_STEPS =  50\n",
    "OUTER_LOOP_ITERATIONS =  5000 #300 #300  # 5000\n",
    "NUM_CLASSES_AND_ONE = 4 + 1\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "GAMMA = 1.0 # 2.0\n",
    "\n",
    "NORMALIZE_FEATURES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b259b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF = 128 \n",
    "nonlin = 'siren'\n",
    "inr_config = {\"in_features\":2, \"out_features\": 1, \"hidden_features\": HF, \"hidden_layers\": 4 }#} + 2} \n",
    "segmentation_config = {'hidden_features':[HF,],#[128, 64],\n",
    "                         'output_features' : NUM_CLASSES_AND_ONE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed65e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "inr_seg_model = models.SirenSegINR(\n",
    "    inr_type='siren',\n",
    "    inr_config=inr_config,\n",
    "    segmentation_config=segmentation_config,\n",
    "    normalize_features=NORMALIZE_FEATURES, #only change\n",
    "\n",
    ").float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb81b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "summary(inr_seg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f949ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner = INRMetaLearner(\n",
    "    model=inr_seg_model,\n",
    "    inner_steps=INNER_STEPS,\n",
    "    config={'inner_lr':1e-4, 'outer_lr':1e-4},\n",
    "    custom_loss_fn = loss_functions.LossFunction(\n",
    "        {'mse_loss':loss_functions.MSELoss(alpha=1), \n",
    "        'focal_loss':loss_functions.FocalSemanticLoss(gamma=GAMMA),\n",
    "        # 'dice_loss':loss_functions.DiceLossMonai(),\n",
    "        },\n",
    "    ),\n",
    "    inner_loop_loss_fn=None, # handled internally by inner loop gradient update and computation. Uses the custom loss function.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173e375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_tmp = alpine.utils.coords.get_coords2d(RES, RES).float().cuda()[None,...]\n",
    "print(coords_tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9efb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataloaders.TorchMRIDataloader(json_file=config_file, mode='train', resolution=RES, coords=coords_tmp, config={'augment':RANDOM_AUGMENT})\n",
    "val_ds = dataloaders.TorchMRIDataloader(json_file=config_file, mode='val', resolution=RES, coords=coords_tmp, config={'augment':RANDOM_AUGMENT,}, )\n",
    "test_ds = dataloaders.TorchMRIDataloader(json_file=config_file, mode='test', resolution=RES, coords=coords_tmp, config={'augment':RANDOM_AUGMENT})\n",
    "print(len(train_ds), len(val_ds), len(test_ds))\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=1, shuffle=False)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=1, shuffle=True)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2c08ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights = deepcopy(meta_learner.model_params)\n",
    "best_inr_weights = None\n",
    "best_classifier_weights = None\n",
    "val_dice_score = []\n",
    "val_iou_scores = []\n",
    "val_psnr_scores = []\n",
    "best_val_psnr = 0\n",
    "best_val_dice_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9fd705",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(OUTER_LOOP_ITERATIONS//len(train_dl)):\n",
    "    pbar = tqdm(enumerate(train_dl), total=len(train_dl))\n",
    "    for ix, data in pbar:\n",
    "        img = data['img'].float().cuda()\n",
    "        seg = data['seg'].float().cuda()\n",
    "        coords = data['coords'].float().cuda()\n",
    "\n",
    "        loss, loss_info = meta_learner.forward(coords, {'gt':img, 'seg':seg, 'resolution' : data['resolution'] ,'seg_integer':data['seg_integer'].cuda().long()})\n",
    "        psnr = -10 * np.log10(loss_info.get('mse_loss',0.01))\n",
    "        # pbar.set_description(f\"Loss: {loss.item():.5f} ce={loss_info['ce_loss']:.5f}, PSNR = {psnr.item():.5f} Dice={loss_info['dice_loss']:.5f}\")\n",
    "        pbar.set_description(f\"Loss: {loss.item():.5f} PSNR = {psnr.item():.5f} Dice={loss_info.get('dice_loss',-1):.4f} FL={loss_info.get('focal_loss', -1):.5f} TV={loss_info.get('tv_loss',-1):.5f}\")\n",
    "        pbar.refresh()\n",
    "\n",
    "        if ix % VAL_META_STEPS == 0 and ix > 0:\n",
    "        # if i % VAL_META_STEPS == 0 and i > 0:\n",
    "\n",
    "            val_dice_score = []\n",
    "            val_iou_scores = []\n",
    "            val_psnr_scores = []\n",
    "            \n",
    "            for val_ix, val in enumerate(val_dl):\n",
    "                val_img = val['img'].float().cuda()\n",
    "                val_seg = val['seg'].float().cuda()\n",
    "                val_coords = val['coords'].float().cuda()\n",
    "\n",
    "                # with torch.no_grad():\n",
    "                render = meta_learner.render_inner_loop(val_coords, val_img, inner_loop_steps=VAL_STEPS)\n",
    "                segmentation_output = render['output']['segmentation_output'].detach()#[0].detach().reshape(RES, RES, -1).cpu().numpy()\n",
    "                segmentation_output = nn.functional.softmax(segmentation_output, dim=-1)\n",
    "                segmentation_output = segmentation_output.argmax(dim=-1).detach().reshape(RES, RES, -1).cpu().numpy()\n",
    "                img_recon = render['output']['inr_output'][0].reshape(RES, RES, -1).detach().cpu().numpy()\n",
    "                segmentation_output_onehot = utils.convert_tensor_to_onehot(torch.tensor(segmentation_output.squeeze()), num_classes=NUM_CLASSES_AND_ONE)\n",
    "                \n",
    "                mse_val = img_recon.flatten() - val_img[0].detach().cpu().numpy().flatten()\n",
    "                mse_val = np.mean(mse_val**2)\n",
    "                psnr = psnr = -10 * np.log10(mse_val)\n",
    "                dice_score = metrics.multiclass_dice_score(segmentation_output_onehot, val['seg'].detach().reshape(RES, RES,-1).cpu(), num_classes=NUM_CLASSES_AND_ONE)\n",
    "                \n",
    "\n",
    "                val_dice_score.append(float(dice_score.item()))\n",
    "                val_psnr_scores.append(float(psnr))\n",
    "\n",
    "            \n",
    "            if np.mean(val_dice_score) > best_val_dice_score:\n",
    "                best_val_psnr = np.mean(val_psnr_scores)\n",
    "                best_val_dice_score = np.mean(val_dice_score)\n",
    "                best_weights = deepcopy(meta_learner.model_params)\n",
    "                best_inr_weights = deepcopy(meta_learner.get_inr_parameters())\n",
    "                best_classifier_weights = deepcopy(meta_learner.get_segmentation_parameters())\n",
    "                best_idx= ix\n",
    "                print('updated dice score to ', best_val_dice_score)\n",
    "\n",
    "            print(f\"Mean PSNR={np.mean(val_psnr_scores):.5f} +/- {np.std(val_psnr_scores):.5f}\")\n",
    "            print(f\"Mean Dice={np.mean(val_dice_score):.5f} +/- {np.std(val_dice_score):.5f}\")\n",
    "        \n",
    "\n",
    "print(\"Best weights from Dice=\", best_val_dice_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a99a819",
   "metadata": {},
   "source": [
    "## Finetune MetaSeg's segmentation head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1d20af",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_finetune_data = []\n",
    "\n",
    "inr_initialization_weights = deepcopy(best_inr_weights)\n",
    "\n",
    "pbar_gen_inr_traindata = tqdm(enumerate(train_dl), total=len(train_dl), position=1)\n",
    "for train_ix, train_data in pbar_gen_inr_traindata:\n",
    "    train_coords = train_data['coords'].float().cuda()\n",
    "    train_img = train_data['img'].float().cuda()\n",
    "    train_seg = train_data['seg'].float().cuda()\n",
    "\n",
    "    # inr_render_model = libINR.models.make_inr_model(type='siren', **inr_config).float().cuda()\n",
    "    inr_render_model = models.INR(**inr_config).float().cuda()\n",
    "    inr_render_model.load_state_dict({k.replace(\"inr.\",\"\"):v.detach().clone() for k,v in deepcopy(inr_initialization_weights).items()})\n",
    "\n",
    "    inr_render_model = inr_render_model.float().cuda()\n",
    "    inr_render_model.compile()\n",
    "\n",
    "    inr_render_model.fit(train_coords, train_img, epochs=TEST_RUN_STEPS, disable_tqdm=True) \n",
    "    train_img_output, train_img_features = inr_render_model.forward_w_features(train_coords)\n",
    "\n",
    "    classifier_finetune_data.append({\n",
    "        'seg': train_seg.detach().clone(),\n",
    "        'img': train_img_output.detach().clone(),\n",
    "        'coords': train_coords.detach().clone(),\n",
    "        'resolution': train_data['resolution'],\n",
    "        'features': train_img_features[-2].detach().clone() # input to classifier\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9052c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "classifier_validation_data = []\n",
    "\n",
    "pbar_gen_inr_valdata = tqdm(enumerate(val_dl), total=len(val_dl), position=1)\n",
    "for val_ix, val_data in pbar_gen_inr_valdata:\n",
    "    val_coords = val_data['coords'].float().cuda()\n",
    "    val_img = val_data['img'].float().cuda()\n",
    "    val_seg = val_data['seg'].float().cuda()\n",
    "\n",
    "    # inr_render_model_val = libINR.models.make_inr_model(type='siren', **inr_config).float().cuda()\n",
    "    inr_render_model_val = models.INR(**inr_config).float().cuda()\n",
    "    inr_render_model_val.load_state_dict({k.replace(\"inr.\",\"\"):v.detach().clone() for k,v in deepcopy(inr_initialization_weights).items()})\n",
    "\n",
    "    inr_render_model_val = inr_render_model_val.float().cuda()\n",
    "    inr_render_model_val.compile()\n",
    "\n",
    "    inr_render_model_val.fit(val_coords, val_img, epochs=TEST_RUN_STEPS, disable_tqdm=True) \n",
    "    val_img_output, val_img_features = inr_render_model_val.forward_w_features(val_coords)\n",
    "\n",
    "    classifier_validation_data.append({\n",
    "        'seg': val_seg.detach().clone(),\n",
    "        'img': val_img_output.detach().clone(),\n",
    "        'coords': val_coords.detach().clone(),\n",
    "        'resolution': val_data['resolution'],\n",
    "        'features': val_img_features[-2].detach().clone() # input to classifier\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcb1cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_FINETUNE_EPOCHS = 4001\n",
    "# prepare classifier\n",
    "classifier_weights = deepcopy({k.replace(\"segmentation_head.segmentation_head\",\"segmentation_head\"):v.clone().detach() for k,v in best_classifier_weights.items()})\n",
    "classifier_model = deepcopy(inr_seg_model.segmentation_head)\n",
    "classifier_model.load_state_dict(classifier_weights)\n",
    "\n",
    "classifier_opt = torch.optim.Adam(classifier_model.parameters(), lr=5e-5)\n",
    "print(classifier_model, list(classifier_weights.keys()), list(classifier_model.state_dict().keys()))\n",
    "\n",
    "finetune_classifier_loss_fn = loss_functions.LossFunction({'focal_loss':loss_functions.FocalSemanticLoss(gamma=GAMMA)})\n",
    "\n",
    "final_classifier_weights = None\n",
    "best_val_score = 1e7\n",
    "\n",
    "pbar_epochs = tqdm(range(CLASSIFIER_FINETUNE_EPOCHS), position=0)\n",
    "for epoch in pbar_epochs:\n",
    "    \n",
    "    avg_loss_per_set = 0.0\n",
    "\n",
    "    for train_ix, train_data in enumerate(classifier_finetune_data):\n",
    "        train_seg = train_data['seg'].float().cuda()\n",
    "        classifier_input = train_data['features'].float().cuda()\n",
    "        if NORMALIZE_FEATURES:\n",
    "            classifier_input = nn.functional.normalize(classifier_input, dim=-1)\n",
    "\n",
    "        classifier_opt.zero_grad()\n",
    "        classifier_output = classifier_model(classifier_input)\n",
    "        loss, loss_info = finetune_classifier_loss_fn({'output':{'segmentation_output':classifier_output.squeeze(1)}, 'seg':train_seg})\n",
    "        loss.backward()\n",
    "        classifier_opt.step()\n",
    "        # lr_scheduler.step()\n",
    "\n",
    "        avg_loss_per_set += float(loss.item())\n",
    "        # pbar.set_description(f\"Loss: {loss.item():.5f} ce={loss_info['ce_loss']:.5f}, PSNR = {psnr.item():.5f} Dice={loss_info['dice_loss']:.5f}\")\n",
    "    avg_loss_per_set /= len(train_dl)\n",
    "    pbar_epochs.set_description(f\"Loss (clf): {avg_loss_per_set:.5f}. Best Val Loss(clf): {best_val_score:.5f}\")\n",
    "    pbar_epochs.refresh()\n",
    "\n",
    "    if epoch % VAL_META_STEPS == 0:\n",
    "        with torch.no_grad():\n",
    "            avg_val_loss = 0.0\n",
    "            for val_ix, val_data in enumerate(classifier_validation_data):\n",
    "                val_seg = val_data['seg'].float().cuda()\n",
    "                classifier_val_input = val_data['features'].float().cuda()\n",
    "                if NORMALIZE_FEATURES:\n",
    "                    classifier_val_input = nn.functional.normalize(classifier_val_input, dim=-1)\n",
    "                \n",
    "                classifier_val_output = classifier_model(classifier_val_input)\n",
    "                val_loss, val_loss_info = finetune_classifier_loss_fn({'output':{'segmentation_output':classifier_val_output.squeeze(1)}, 'seg':val_seg})\n",
    "\n",
    "                avg_val_loss += float(val_loss.item())\n",
    "            avg_val_loss = avg_val_loss / len(val_dl)\n",
    "            pbar_epochs.set_description(f\"Loss (clf): {avg_loss_per_set:.5f} Val Loss (clf): {avg_val_loss:.5f}\")\n",
    "            pbar_epochs.refresh()\n",
    "\n",
    "            if avg_val_loss < best_val_score:\n",
    "                best_val_score = avg_val_loss\n",
    "                final_classifier_weights = deepcopy(classifier_model.state_dict())\n",
    "                tqdm.write(f'updated best val score to {best_val_score}')\n",
    "            else:\n",
    "                tqdm.write(f'No improvement in val score {epoch}')\n",
    "\n",
    "\n",
    "    # print(f\"Avg loss for this epoch ({epoch}/{CLASSIFIER_FINETUNE_EPOCHS}) = {avg_loss_per_set:.5f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a87cd4",
   "metadata": {},
   "source": [
    "## Test-time. Fit Pixels, Get Labels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd953e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inr_initialization_weights = deepcopy(best_inr_weights)\n",
    "\n",
    "classifier_model.load_state_dict(final_classifier_weights)\n",
    "classifier_model.eval()\n",
    "\n",
    "pbar_test = tqdm(enumerate(test_dl), total=len(test_dl))\n",
    "dice_scores = []\n",
    "psnr_scores = []\n",
    "# TEST_RUN_STEPS = 50\n",
    "TEST_RUN_STEPS = 100\n",
    "for test_ix, test_data in pbar_test:\n",
    "    test_coords = test_data['coords'].float().cuda()\n",
    "    test_img = test_data['img'].float().cuda()\n",
    "    test_seg = test_data['seg'].float().cuda()\n",
    "\n",
    "    # test_inr_render_model = libINR.models.make_inr_model(type='siren', **inr_config).float().cuda()\n",
    "    test_inr_render_model = models.INR(**inr_config).float().cuda()\n",
    "    test_inr_render_model.load_state_dict({k.replace(\"inr.\",\"\"):v.detach().clone() for k,v in deepcopy(inr_initialization_weights).items()})\n",
    "\n",
    "    test_inr_render_model = test_inr_render_model.float().cuda()\n",
    "    test_inr_render_model.compile()\n",
    "\n",
    "    test_inr_render_model.fit(test_coords, test_img, epochs=TEST_RUN_STEPS, disable_tqdm=True) \n",
    "    test_img_output, test_img_features = test_inr_render_model.forward_w_features(test_coords)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        classifier_input = test_img_features[-2].detach().clone()\n",
    "        if NORMALIZE_FEATURES:\n",
    "            classifier_input = nn.functional.normalize(classifier_input, dim=-1)\n",
    "        classifier_output = classifier_model(classifier_input)\n",
    "        seg_probs = nn.functional.softmax(classifier_output, dim=-1)\n",
    "        seg_probs = seg_probs.argmax(dim=-1).detach().reshape(RES, RES, -1).cpu().numpy()\n",
    "\n",
    "        seg_probs_onehot = utils.convert_tensor_to_onehot(torch.tensor(seg_probs.squeeze(-1)), num_classes=NUM_CLASSES_AND_ONE)\n",
    "\n",
    "   \n",
    "    psnr = metrics.psnr2(test_img.reshape(RES, RES).detach().cpu().numpy(), test_img_output.reshape(RES, RES).detach().cpu().numpy())\n",
    "    dice = metrics.multiclass_dice_score(seg_probs_onehot, test_seg.reshape(RES, RES,-1).cpu(), num_classes=NUM_CLASSES_AND_ONE)\n",
    "    psnr_scores.append(float(psnr))\n",
    "    dice_scores.append(float(dice))\n",
    "    # vis.plot_result_row(titles=['Seg', 'Seg(GT)'], \n",
    "    #                     imgs=[\n",
    "    #                             seg_probs,\n",
    "    #                             test_data['seg_integer'].reshape(RES, RES,-1).cpu().numpy()\n",
    "    #                         ], save=None, show=True)\n",
    "    \n",
    "    pbar_test.set_description(f\"Test Sample: {test_ix}/{len(test_dl)} PSNR = {float(psnr):.5f} Dice={float(dice):.5f}\")\n",
    "    pbar_test.refresh()\n",
    "\n",
    "\n",
    "print(\"Average Reconstruction PSNR = \", np.mean(psnr_scores), \"+/-\", np.std(psnr_scores))\n",
    "print(\"Average Segmentation Dice = \", np.mean(dice_scores), \"+/-\", np.std(dice_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848ba9e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
