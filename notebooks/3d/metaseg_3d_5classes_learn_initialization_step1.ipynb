{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f074b3ca",
   "metadata": {},
   "source": [
    "## MetaSeg 3D segmentation STEP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017cf88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b64f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c09b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(422)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f66fdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path as osp\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5c30b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, os.path as osp\n",
    "import torch\n",
    "import alpine\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a21517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../modules')\n",
    "sys.path.append(\"../../\")\n",
    "from learner import INRMetaLearner\n",
    "import dataloaders\n",
    "\n",
    "import models\n",
    "import loss_functions\n",
    "import metrics\n",
    "import utils\n",
    "import vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac53be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cb6533",
   "metadata": {},
   "source": [
    "## Enter dataset path below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f376626",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"\" ## ENTER DATSET PATH HERE!!!!!!!!!!!\n",
    "config_file = \"../../config/oasis_splits_3d.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab981594",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_data = json.load(open(config_file, 'r'))\n",
    "train_files = files_data['train']\n",
    "val_files = files_data['val']\n",
    "test_files = files_data['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55cd3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check overlap for any samples.\n",
    "print(len(train_files), len(val_files), len(test_files))\n",
    "set_train = set([x['img'] for x in train_files])\n",
    "set_val = set([x['img'] for x in val_files])\n",
    "set_test = set([x['img'] for x in test_files])\n",
    "\n",
    "if len(set_train.intersection(set_val)) > 0 or  len(set_train.intersection(set_test)) > 0 or  len(set_val.intersection(set_test)) > 0:\n",
    "    print(\"WARNING: OVERLAPPING DATA SPLITS\")\n",
    "else:\n",
    "    print(\"No overlap in data splits. GOOD TO GO!!!!!!!!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b598ecb",
   "metadata": {},
   "source": [
    "## Some hyperparameters for the optimization process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3a2d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "INNER_STEPS = 2\n",
    "RANDOM_AUGMENT = False\n",
    "TEST_RUN_STEPS = VAL_STEPS  = 300 #for full res\n",
    "SKIP_PIXELS = 2\n",
    "VAL_META_STEPS = 100\n",
    "OUTER_LOOP_ITERATIONS =  5000  # 5000\n",
    "NUM_CLASSES = 4\n",
    "NUM_CLASSES_AND_ONE = NUM_CLASSES + 1\n",
    "# RES = (160, 192, 224)\n",
    "\n",
    "RES = (160,160,200)\n",
    "VAL_RES = RES = [160//SKIP_PIXELS, 160//SKIP_PIXELS, 200//SKIP_PIXELS]\n",
    "\n",
    "NORMALIZE_FEATURES = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad57de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlin = 'siren'\n",
    "inr_config = {\"in_features\":3, \"out_features\": 1, \"hidden_features\": 256, \"hidden_layers\": 4, }#\"first_omega_0\":200.0, 'hidden_omega_0':200.0} \n",
    "segmentation_config = {'hidden_features':[256,],#[128, 64],\n",
    "                         'output_features' : NUM_CLASSES_AND_ONE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1129098",
   "metadata": {},
   "outputs": [],
   "source": [
    "inr_seg_model = models.SirenSegINR(\n",
    "    inr_type='siren',\n",
    "    inr_config=inr_config,\n",
    "    segmentation_config=segmentation_config,\n",
    "    normalize_features=NORMALIZE_FEATURES,\n",
    "    ).float().cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577320b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner = INRMetaLearner(\n",
    "    model=inr_seg_model,\n",
    "    inner_steps=INNER_STEPS,\n",
    "    config={'inner_lr':1e-4, 'outer_lr':1e-4},\n",
    "    custom_loss_fn = loss_functions.LossFunction(\n",
    "        {'mse_loss':loss_functions.MSELoss(alpha=1.0, reduction='weighted_mean', zero_weight=0.1), \n",
    "         'focal_loss' : loss_functions.FocalSemanticLoss(alpha=1.0, gamma=3.0),\n",
    "        },\n",
    "    ),\n",
    "    outer_optimizer='adam',\n",
    "    inner_loop_loss_fn=None, # uses default loss fn.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8f2aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_tmp = alpine.utils.coords.get_coords2d(RES[0], RES[1]).float().cuda()[None,...]\n",
    "print(coords_tmp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597111d0",
   "metadata": {},
   "source": [
    "Set `NUM_VAL_EXAMPLES` variable. For faster evaluation, you can reduce `NUM_VAL_EXAMPLES`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5a3c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_VAL_EXAMPLES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a91adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataloaders.TorchMRI3D_Dataloader(json_file=config_file, mode='train', resolution=RES, coords=coords_tmp, config={'augment':RANDOM_AUGMENT}, num_classes=NUM_CLASSES, skip_pixels=SKIP_PIXELS)\n",
    "val_ds = dataloaders.TorchMRI3D_Dataloader(json_file=config_file, mode='val', resolution=RES, coords=coords_tmp, config={'augment':RANDOM_AUGMENT, 'N_samples':NUM_VAL_EXAMPLES}, num_classes=NUM_CLASSES, skip_pixels=SKIP_PIXELS)\n",
    "test_ds = dataloaders.TorchMRI3D_Dataloader(json_file=config_file, mode='test', resolution=RES, coords=coords_tmp, config={'augment':RANDOM_AUGMENT}, num_classes=NUM_CLASSES, skip_pixels=SKIP_PIXELS)\n",
    "print(len(train_ds), len(val_ds), len(test_ds))\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=1, shuffle=False)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=1, shuffle=False)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d06181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights = deepcopy(meta_learner.model_params)\n",
    "best_inr_weights = None\n",
    "best_classifier_weights = None\n",
    "val_dice_score = []\n",
    "val_iou_scores = []\n",
    "val_psnr_scores = []\n",
    "best_val_psnr = 0\n",
    "best_val_dice_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8117b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(OUTER_LOOP_ITERATIONS//len(train_dl)):\n",
    "    \n",
    "    pbar = tqdm(enumerate(train_dl), total=len(train_dl))\n",
    "    for ix, data in pbar:\n",
    "        img = data['img'].float().cuda()\n",
    "        seg = data['seg'].float().cuda()\n",
    "        coords = data['coords'].float().cuda()\n",
    "        seg_integer = data['seg_integer'].float().cuda()\n",
    "        loss, loss_info = meta_learner.forward(coords, {'gt':img, 'seg':seg, 'seg_integer':seg_integer,'resolution' : data['resolution']})\n",
    "        psnr = -10 * np.log10(loss_info.get('mse_loss',0.01))\n",
    "        pbar.set_description(f\"Loss: {loss.item():.5f} PSNR = {psnr.item():.5f} Dice={loss_info.get('dice_loss',-1):.4f} FL={loss_info.get('focal_loss', -1):.5f} TV={loss_info.get('tv_loss',-1):.5f}\")\n",
    "        pbar.refresh()\n",
    "\n",
    "        if ix % VAL_META_STEPS == 0:\n",
    "\n",
    "            val_dice_score = []\n",
    "            val_iou_scores = []\n",
    "            val_psnr_scores = []\n",
    "            \n",
    "            for val_ix, val in tqdm(enumerate(val_dl), total=len(val_dl), position=1):\n",
    "                val_img = val['img'].float().cuda()\n",
    "                val_seg = val['seg'].float().cuda()\n",
    "                val_coords = val['coords'].float().cuda()\n",
    "                val_seg_integer = val['seg_integer'].float().cuda()\n",
    "\n",
    "                render = meta_learner.render_inner_loop(val_coords, val_img, inner_loop_steps=VAL_STEPS)\n",
    "                segmentation_output = render['output']['segmentation_output'].detach()#[0].detach().reshape(RES, RES, -1).cpu().numpy()\n",
    "                segmentation_output = nn.functional.softmax(segmentation_output, dim=-1)\n",
    "                segmentation_output = segmentation_output.argmax(dim=-1).detach().reshape(VAL_RES).cpu().numpy()\n",
    "                img_recon = render['output']['inr_output'][0].reshape(VAL_RES).detach().cpu().numpy()\n",
    "                segmentation_output_onehot = torch.nn.functional.one_hot(torch.tensor(segmentation_output), num_classes=NUM_CLASSES_AND_ONE)\n",
    "                val_reshaped = val_img[0].detach().cpu().numpy().reshape(VAL_RES)\n",
    "                val_seg_reshaped = val_seg_integer.detach().cpu().numpy().reshape(VAL_RES)\n",
    "                # for k_x in range(0, VAL_RES[-1], VAL_RES[-1]//4):\n",
    "                #     plt.figure()\n",
    "                #     plt.subplot(121)\n",
    "                #     plt.imshow(np.concatenate([img_recon[...,k_x], val_reshaped[...,k_x]], axis=1))\n",
    "                #     plt.subplot(122)\n",
    "                #     plt.imshow(np.concatenate([segmentation_output[...,k_x], val_seg_reshaped[...,k_x]],axis=1))\n",
    "                #     plt.title(f\"Iteration={ix}, Val Iteration={val_ix}\")\n",
    "                #     plt.show()\n",
    "                mse_val = img_recon[...,40:80].flatten() - val_reshaped[...,40:80].flatten()\n",
    "                mse_val = np.mean(mse_val**2)\n",
    "                psnr = psnr = -10 * np.log10(mse_val)\n",
    "                val_psnr_scores.append(float(psnr))\n",
    "                dice_score = metrics.multiclass_dice_score_3d(segmentation_output_onehot.cuda(), val_seg.reshape(VAL_RES[0], VAL_RES[1], VAL_RES[2], -1).cuda(), num_classes=NUM_CLASSES_AND_ONE)\n",
    "                val_dice_score.append(float(dice_score.item()))\n",
    "\n",
    "            \n",
    "            if np.mean(val_dice_score) > best_val_dice_score:\n",
    "                best_val_psnr = np.mean(val_psnr_scores)\n",
    "                best_val_dice_score = np.mean(val_dice_score)\n",
    "                best_weights = deepcopy(meta_learner.model_params)\n",
    "                best_inr_weights = deepcopy(meta_learner.get_inr_parameters())\n",
    "                best_classifier_weights = deepcopy(meta_learner.get_segmentation_parameters())\n",
    "                best_idx= ix\n",
    "                print('updated dice score to ', best_val_dice_score)\n",
    "                torch.save({'inr_seg_model':inr_seg_model.state_dict(),\n",
    "                            'best_inr_weights':best_inr_weights,\n",
    "                            'best_classifier_weights':best_classifier_weights}, \n",
    "                            f\"./dumps/weights3d_num_classes_{NUM_CLASSES}_IS_{INNER_STEPS}.pth\")\n",
    "\n",
    "            print(f\"Mean PSNR={np.mean(val_psnr_scores):.5f} +/- {np.std(val_psnr_scores):.5f}\")\n",
    "            \n",
    "            print(f\"Mean Dice={np.mean(val_dice_score):.5f} +/- {np.std(val_dice_score):.5f}\")\n",
    "        \n",
    "\n",
    "print(\"Best weights from Dice=\", best_val_dice_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5a3932",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'inr_seg_model':inr_seg_model.state_dict(),'best_inr_weights':best_inr_weights,\n",
    "                'best_classifier_weights':best_classifier_weights}, f\"./dumps/weights3d_num_classes_{NUM_CLASSES}_IS_{INNER_STEPS}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed911370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
