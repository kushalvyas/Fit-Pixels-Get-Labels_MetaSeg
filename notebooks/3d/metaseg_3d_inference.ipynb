{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference.\n",
    "\n",
    "Before running this script, \n",
    "\n",
    "1. Please run step1.ipynb: to generate meta learned initialization for the INR\n",
    "2. Please run step2.ipynb with `SAVE_FEATURE_VECS = True`. This will generate INR feature vectors for train, val, test sets and store them into './dumps/intermediate_vectors'. This is done because its computationaly simplicity. \n",
    "3. Re-run step2.ipynb with `SAVE_FEATURE_VECS = False` . This will start finetuning the segmentation head of metaseg using these saved feature vectors. Please note that thes training segmentation head for 3D data is a tiring and long process and reaching converegence in a day or so approximately. To get best results, use smaller learning rates (>= 5e-5) and let optimization run for longer. Depending on yuor data, you may have to adjust the $\\gamma$ parameter in Focal loss. Please read how $\\gamma$ controls the focal loss properties in the \"Focal Loss for Dense Object Detection by Lin et.al, ICCV 2017\". \n",
    "\n",
    "4. Once your model is trained, you can run the inference codes. This will directly test on the test-set feature-vectors saved as output of `step2.ipynb`. This script does not render the 3D point clouds. \n",
    "\n",
    "5. Incase you want to render 3D point clouds, please fit the signal using the initialization obtained from `step1.ipynb`. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']  = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(422)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path as osp\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import alpine\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, os.path as osp\n",
    "import torch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import libINR.models, libINR.utils\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../modules')\n",
    "sys.path.append(\"../../\")\n",
    "from learner import INRMetaLearner\n",
    "import dataloaders\n",
    "\n",
    "import models\n",
    "import loss_functions\n",
    "import metrics\n",
    "import utils\n",
    "import vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INNER_STEPS = 2\n",
    "RANDOM_AUGMENT = False\n",
    "TEST_RUN_STEPS = VAL_STEPS  = 100\n",
    "SKIP_PIXELS = 2\n",
    "VAL_META_STEPS = 100\n",
    "OUTER_LOOP_ITERATIONS =  5000  # 5000\n",
    "NUM_CLASSES = 4\n",
    "NUM_CLASSES_AND_ONE = NUM_CLASSES + 1\n",
    "# RES = (160, 192, 224)\n",
    "\n",
    "RES = (160,160,200)\n",
    "VAL_RES = RES = [160//SKIP_PIXELS, 160//SKIP_PIXELS, 200//SKIP_PIXELS]\n",
    "\n",
    "NORMALIZE_FEATURES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RES, VAL_RES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"../../config/oasis_splits_3d.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlin = 'siren'\n",
    "inr_config = {\"in_features\":3, \"out_features\": 1, \"hidden_features\": 256, \"hidden_layers\": 4, }#\"first_omega_0\":200.0, 'hidden_omega_0':200.0} \n",
    "segmentation_config = {'hidden_features':[256,],#[128, 64],\n",
    "                         'output_features' : NUM_CLASSES_AND_ONE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inr_seg_model = models.SirenSegINR(\n",
    "    inr_type='siren',\n",
    "    inr_config=inr_config,\n",
    "    segmentation_config=segmentation_config,\n",
    "    normalize_features=NORMALIZE_FEATURES, #only change\n",
    "\n",
    ").float().cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_tmp = alpine.utils.coords.get_coords3d(RES[0], RES[1], RES[2]).float().cuda()[None,...]\n",
    "print(coords_tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATHS = \"./dumps/intermediate_vectors\" # savepath from step2.ipynb\n",
    "data_dir_feature_vecs = osp.join(SAVE_PATHS, \"test\")\n",
    "\n",
    "\n",
    "test_clf_ds = dataloaders.CLFFeature(data_dir_feature_vecs, mode='test')\n",
    "\n",
    "test_clf_dl = torch.utils.data.DataLoader(test_clf_ds, batch_size=1, shuffle=False, num_workers=1, pin_memory=False)\n",
    "\n",
    "print(len(test_clf_dl))\n",
    "print(len(test_clf_ds.all_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_clf_weights = \"./weights/classifierfinal_weights_LR_5e-05_exp_gamma_3.0_INR_2it_skip_pixels_2_parallel_test.pth\"\n",
    "\n",
    "weights_saved = torch.load(segmentation_clf_weights)\n",
    "\n",
    "final_clf_weights = weights_saved['final_clf_weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = deepcopy(inr_seg_model.segmentation_head)\n",
    "classifier_model.load_state_dict(final_clf_weights)\n",
    "classifier_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just compute DICE metrics for segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pbar_test = tqdm(enumerate(test_clf_dl), total=len(test_clf_dl))\n",
    "dice_scores = []\n",
    "psnr_scores = []\n",
    "psnr = 0\n",
    "dice = 0\n",
    "TEST_RUN_STEPS = 100 \n",
    "for test_ix, test_data in pbar_test:\n",
    "    \n",
    "    test_features = test_data['features'].float().cuda().squeeze(0).squeeze(0)\n",
    "    test_img = test_data['img'].float().cuda()\n",
    "    test_seg = test_data['seg'].float().cuda()\n",
    "\n",
    "    print(test_features.shape, test_img.shape, test_seg.shape)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        classifier_input = test_features.detach().clone()\n",
    "        classifier_output = classifier_model(classifier_input).unsqueeze(0).unsqueeze(0)\n",
    "        seg_probs = nn.functional.softmax(classifier_output, dim=-1)\n",
    "        seg_probs = seg_probs.argmax(dim=-1).reshape(VAL_RES).detach().cpu().numpy()\n",
    "        seg_probs_onehot = torch.nn.functional.one_hot(torch.from_numpy(seg_probs), num_classes=NUM_CLASSES_AND_ONE)\n",
    "\n",
    "    test_seg_reshaped = test_seg.reshape(VAL_RES[0], VAL_RES[1], VAL_RES[2], -1)\n",
    "    test_seg_int = torch.argmax(test_seg_reshaped, dim=-1).detach().cpu().numpy()\n",
    "    dice = metrics.multiclass_dice_score_3d(seg_probs_onehot.cuda(), test_seg_reshaped.cuda(), num_classes=NUM_CLASSES_AND_ONE)\n",
    "    dice_3d = float(dice.item())\n",
    "    dice_scores.append(float(dice))\n",
    "    print(\"Dice score for test sample \", test_ix, \" = \", dice)\n",
    "\n",
    "    n_frames = seg_probs.shape[-1]\n",
    "    local_labels = []\n",
    "    local_dice = []\n",
    "    # for k in range(5, n_frames - 5, (n_frames-10)//6):\n",
    "    for k in range(n_frames):\n",
    "        # local_labels.append(seg_probs[...,k].detach().cpu().numpy())\n",
    "        dice_2d = metrics.multiclass_dice_score(torch.nn.functional.one_hot(torch.from_numpy(seg_probs[...,k]).cuda(), num_classes=NUM_CLASSES_AND_ONE),\n",
    "                                                test_seg_reshaped[...,k,:].cuda(), num_classes=NUM_CLASSES_AND_ONE)\n",
    "        dice_2d = float(dice_2d.item())\n",
    "        local_dice.append(dice_2d)\n",
    "        \n",
    "    \n",
    "    print(f\"Test Sample: {test_ix}/{len(test_clf_dl)} Dice={float(dice):.5f}. Img Dice={np.mean(local_dice)}\")\n",
    "    pbar_test.set_description(f\"Test Sample: {test_ix}/{len(test_clf_dl)} Dice={float(dice):.5f}\")\n",
    "    pbar_test.refresh()\n",
    "    print(\"---\"*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average Segmentation Dice = \", np.mean(dice_scores), \"+/-\", np.std(dice_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
